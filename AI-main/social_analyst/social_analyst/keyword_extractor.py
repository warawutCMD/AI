from keybert import KeyBERT
from typing import List
from sentence_transformers import SentenceTransformer
from pythainlp.tokenize import word_tokenize
from pythainlp.corpus.common import thai_stopwords
import re

class ThaiKeywordExtractor:
    def __init__(self, tokenizer_engine="attacut"):
        self.model = SentenceTransformer("paraphrase-multilingual-mpnet-base-v2")
        self.kw_model = KeyBERT(self.model)
        self.tokenizer_engine = tokenizer_engine
        self.stop_words = self.get_preprocessed_stopwords()

    def clean_text(self, text: str) -> str:
        text = re.sub(r"[^\u0E00-\u0E7Fa-zA-Z0-9\s]", "", text)
        text = re.sub(r"\s+", " ", text)
        return text.strip()

    def preprocess_text(self, texts: List[str]) -> str:
        cleaned = [self.clean_text(t) for t in texts if t and t.strip()]
        if not cleaned:
            return ""

        combined = " ".join(cleaned)
        tokens = word_tokenize(combined, engine=self.tokenizer_engine)

        # üí• ‡∏Å‡∏£‡∏≠‡∏á token ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß > 1 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà stopword
        tokens = [token.strip() for token in tokens if token.strip() and len(token.strip()) > 1 and token not in self.stop_words]

        final_text = " ".join(tokens)
        print("üîç Clean tokens:", tokens)
        print("üîç Combined clean text:", final_text)
        return final_text


    def get_preprocessed_stopwords(self) -> List[str]:
        cleaned = [self.clean_text(w) for w in thai_stopwords()]
        tokenized = [token for stopword in cleaned for token in word_tokenize(stopword, engine=self.tokenizer_engine)]
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° stopwords custom
        additional = ["‡πÜ", "‡∏Ø", "‡πÅ‡∏•‡∏∞", "‡∏´‡∏£‡∏∑‡∏≠", "‡∏ß‡πà‡∏≤", "‡πÅ‡∏ï‡πà", "‡∏Ñ‡∏∑‡∏≠", "‡πÑ‡∏î‡πâ", "‡πÉ‡∏´‡πâ", "‡πÇ‡∏î‡∏¢", "‡∏Å‡πá", "‡πÄ‡∏õ‡πá‡∏ô", "‡∏ó‡∏µ‡πà", "‡∏Ç‡∏≠‡∏á", "‡∏Å‡∏±‡∏ö"]
        full_stopwords = set(tokenized + additional)
        # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏≠‡∏≤‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß‡∏Å‡∏ß‡πà‡∏≤ 1 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
        full_stopwords = {w for w in full_stopwords if len(w) > 1}
        return list(full_stopwords)

    def extract_keywords(self, texts: List[str], top_n: int = 5) -> List[str]:
        combined_text = self.preprocess_text(texts)
        if not combined_text:
            return []

        keywords = self.kw_model.extract_keywords(
            combined_text,
            keyphrase_ngram_range=(1, 3),
            stop_words=self.stop_words,
            use_maxsum=True,
            nr_candidates=60,
            top_n=top_n,
        )

        print("üîç Raw keywords:", keywords)
        filtered_keywords = [kw[0] for kw in keywords if kw[0] not in self.stop_words]
        return list(dict.fromkeys(filtered_keywords))
